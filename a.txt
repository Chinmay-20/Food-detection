#preprocessing stuff

#part 1 begins
'''
list all images under training
print(os.listdir(os.path.join(filea,"training")))
print()
print()
print()
print()
list all images under validation
print(os.listdir(os.path.join(filea,"validation")))
print()
print()
print()
print()
list all images under testing
print(os.listdir(os.path.join(filea,"evaluation")))
print()
print()
print()
	train.extend(os.listdir(os.path.join(i,'training')))
	
	valid.extend(os.listdir(os.path.join(filea,i)))
	test.extend(os.listdir(os.path.join(filea,i)))
for i in os.listdir(filea):
	if i=="training":
		train.extend(os.listdir(os.path.join(filea,i)))
	elif i=="validation":
		valid.extend(os.listdir(os.path.join(filea,i)))
	elif i=="evaluation":
		test.extend(os.listdir(os.path.join(filea,i)))
'''

train=[]
valid=[]
test=[]

for i in os.listdir(filea):
	if i=="training":
		filet=os.path.join(filea,i)
		for j in os.listdir(filet):
			train.extend(os.listdir(os.path.join(filet,j)))
	elif i=="validation":
		filev=os.path.join(filea,i)
		for j in os.listdir(filev):
			valid.extend(os.listdir(os.path.join(filev,j)))
	elif i=="evaluation":
		filee=os.path.join(filea,i)
		for j in os.listdir(filee):
			test.extend(os.listdir(os.path.join(filee,j)))


print("[INFO] Number of train images: {} \nNumber of validation images: {} \nNumber of test images: {}".format(len(train),len(valid),len(test)))

#visualization not done 

no_images_per_train_class=[]
train_class_name=[]

print("\n\nTraining")
for i in os.listdir(os.path.join(filea,"training")):
	train_class_name.append(i)
	train_class=os.listdir(os.path.join(filea,"training",i))
	print("[INFO] Number of images in {}={}".format(i,len(train_class)))
	no_images_per_train_class.append(len(train_class))
	
print("[INFO] classes names are {}".format(train_class_name))

no_images_per_val_class=[]
val_class_name=[]

print("\n\nValidation")
for i in os.listdir(os.path.join(filea,"validation")):
	val_class_name.append(i)
	val_class=os.listdir(os.path.join(filea,"validation",i))
	print("[INFO] Number of images in {}={}".format(i,len(val_class)))
	no_images_per_val_class.append(len(val_class))
	
print("[INFO] classes names are {}".format(val_class_name))

no_images_per_test_class=[]
test_class_name=[]

print("\n\nTesting")
for i in os.listdir(os.path.join(filea,"evaluation")):
	test_class_name.append(i)
	test_class=os.listdir(os.path.join(filea,"evaluation",i))
	print("[INFO] Number of images in {}={}".format(i,len(test_class)))
	no_images_per_test_class.append(len(test_class))
	
print("[INFO] classes names are {}".format(test_class_name))

#part 2 begins
#finetuning model checking primary and finetuned model accuracy at same time
basemodel.trainable=True
print(model.summary())

#using earlystopping to exit training if validation is not decreasing even after after certain epochs(patience)
earlystopping=EarlyStopping(monitor="val_loss",mode="min",verbose=1,patience=20)

#for saving the best model
checkpointer=ModelCheckpoint(filepath="output/finetuneweights.hdf5",verbose=1,save_best_only=True)

model.compile(loss="categorical_crossentropy",optimizer=SGD(lr=0.0001,momentum=0.9),metrics=["accuracy"])
print("[INFO] compiled finetuned model")

print("[INFO] training finetuned model")
history=model.fit(train_generator,steps_per_epoch=train_generator.n//32, epochs=10, validation_data=val_generator,validation_steps=val_generator.n//32, callbacks=[earlystopping,checkpointer])

print("[INFO] trained finetuned model")

#part 3 begins
#loading pre-trained model
model.load_weights("output/finetunewieghts.hdf5")

evaluate=model.evaluate_generator(test_generator,steps=test_generator.n//32,verbose=1)

print("Accuracy Test: {}".format(evaluate[1]))

labels = {0: 'Bread', 1: 'Dairy product', 2: 'Dessert', 3:'Egg', 4: 'Fried food', 5:'Meat',6:'Noodles-Pasta',7:'Rice', 8:'Seafood',9:'Soup',10: 'Vegetable-Fruit'}

#loading images and predictions+

prediction=[]
original=[]
image=[]
count=0

for i in os.listdir(os.path.join(filea,"evaluation")):
	for item in os.listdir(os.path.join(filea,"evaluation",i)):
		img=PIL.Image.open(os.path.join(filea,"evaluation",i,item))
	
	img=img.resize((256,256))
	image.append(img)
	img=np.asarray(img,dtype=np.float32)
	img=img/255
	img=img.reshape(-1,256,256,3)
	predict=model.predict(img)
	predict=np.argmax(predict)
	prediction.append(labels[predict])
	original.append(i)
	
print(classification_report(np.asarray(original),np.array(prediction)))

